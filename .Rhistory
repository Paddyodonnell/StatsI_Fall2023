df$genre # Select column
# For each row, value=="Comedy" or "Drama" or "Documentary"?
df$genre=="Comedy" | df$genre=="Drama" | df$genre=="Documentary"
# Select rows with value=="Comedy" or "Drama" or "Documentary"
df[df$genre=="Comedy" |
df$genre=="Drama" |
df$genre=="Documentary", ]
# Install and load tidyverse
# Adopted from: https://stackoverflow.com/questions/4090169/elegant-way-to-check-for-missing-packages-and-install-them
if(!require(tidyverse)){
install.packages("tidyverse")
library(tidyverse)
}
df_s <- subset(df, df$genre %in% c("Comedy","Documentary","Drama"))
View(df_s)
?subset
# Step by step
df$genre # Select column
"Horror" %in% c("Comedy","Documentary","Drama") # Horror is in vector?
"Comedy" %in% c("Comedy", "Documentary","Drama") # Comedy is in vector?
df$genre  %in% c("Comedy","Documentary","Drama") # For each row, value==Comedy or Documentary or Drama?
# Contingency table
table(df_s$genre, # Genre
df_s$critics_rating) # Rating
# Problem: Although we filtered our data
# the underlying levels still exist. Getting rid of
# these, we use the droplevels-function.
class(df_s$genre)
levels(df_s$genre)
df_s$genre <- droplevels(df_s$genre)
# Contingency table
table(df_s$genre, # Genre
df_s$critics_rating) # Rating
# Add marginal distributions
addmargins(table(df_s$genre, # Genre
df_s$critics_rating)) # Rating
# Joint probability
prop.table(table(df_s$genre,
df_s$critics_rating))
63/444
# (A) Conditional probability
# What is the probability of "Rotten",
# conditional on Comedy?
?prop.table()
# Over rows --> Rating conditional on genre
prop.table(table(df_s$genre, # rows
df_s$critics_rating), # columns
margin = 1) # over rows
63/87
# Add marginal distributions
# Over rows --> Rating conditional on genre
addmargins(prop.table(table(df_s$genre,
df_s$critics_rating),
margin = 1)) # over rows
# Round
round(addmargins(prop.table(table(df_s$genre,
df_s$critics_rating),
margin = 1)), 2)
# Step by step
round(0.72413793, 2) # Round to two decimals
# Over columns --> Genre conditional on rating
addmargins(prop.table(table(df_s$genre, # rows
df_s$critics_rating), # columns
margin = 2)) # over columns
63/190
# Bar plot
barplot(prop.table(table(df_s$genre,
df_s$critics_rating), margin=1),
xlab="Ranking",
ylab="Proportions",
main="Critics Rating by Genre",
beside=TRUE,
legend.text = TRUE,
args.legend = list(x=12,
y=0.7,
cex = 0.8,
box.col = "white"))
# Run Chi square test
chisq.test(df_s$genre,
df_s$critics_rating)
# Get working directory
getwd()
# Set working directory
setwd("/Users/hannahfrank/StatsI_Fall2023_prep")
# Set working directory
setwd("/Users/paddy/OneDrive/Documents/GitHub/StatsI_Fall2023")
getwd()
# Load data
df <- read.csv("datasets/fictional_data.csv")
# First step, look at data
View(df)
head(df)
str(df) # Structure of R object
?str
mean(df$income) # Central tendency, mean
var(df$income) # Variability, variance
sd(df$income) # Variability, standard deviation
sd(df$income)/sqrt(length(df$income)) # Variability, standard **error**
# Step by step
df$income # Access variable
length(df$income) # Number of observations
sqrt(length(df$income)) # Take square root
sqrt(19)
# Get summary statistics for entire dataset
summary(df)
# Some quick visualizations, to look at distribution
hist(df$income,
#breaks = 20,
main="Monthly net income",
xlab="Euro")
plot(density(df$incom),
main="Monthly net income",
xlab="Euro")
# Which kind of inferences can we make with regards to the population,
# based on the sample data?
mean(df$income) # Sample mean is estimate for population mean
sd(df$income)/sqrt(length(df$income))
# What do we need?
mean(df$income) # Point estimate
sd(df$income)/sqrt(length(df$income)) # Standard error
# The **approximate** solution
# Lower bound, 95 confidence level
upper_95 = mean(df$income)+(1.96*sd(df$income)/sqrt(length(df$income)))
# Upper bound, 95 confidence level
lower_95 = mean(df$income)-(1.96*sd(df$income)/sqrt(length(df$income)))
length(df$income) # Number of observations
sqrt(length(df$income)) # Take square root
sqrt(19)
# Which kind of inferences can we make with regards to the population,
# based on the sample data?
mean(df$income) # Sample mean is estimate for population mean
sd(df$income)/sqrt(length(df$income))
# What do we need?
mean(df$income) # Point estimate
sd(df$income)/sqrt(length(df$income)) # Standard error
# Step by step
?qnorm
qnorm(0.025) # value for first 2.5%
qnorm(0.975) # value last 2.5%
qnorm(0.025, mean=2, sd=0.4) # Change mean and standard error
# Print
lower_95_n
# The **precise** solution, using normal distribution
# Lower bound, 95 confidence level
lower_95_n <- qnorm(0.025,
mean = mean(df$incom),
sd = (sd(df$income)/sqrt(length(df$income))))
# Upper bound, 95 confidence level
upper_95_n <- qnorm(0.975,
mean = mean(df$income),
sd = (sd(df$incom)/sqrt(length(df$income))))
qnorm(0.025) # value for first 2.5%
qnorm(0.975) # value last 2.5%
qnorm(0.025, mean=2, sd=0.4) # Change mean and standard error
# Print
lower_95_n
mean(df$income)
upper_95_n
# The **precise** solution, using t distribution
t_score <- qt(0.995, df=length(df$income)-1)
lower_99_t <- mean(df$income)-(t_score)*(sd(df$income)/sqrt(length(df$income)))
upper_99_t <- mean(df$income)+(t_score)*(sd(df$income)/sqrt(length(df$income)))
# Step by step
?qt
qt(0.005, df=length(df$income)-1) # critical value for first 0.5%
qt(0.995, df=length(df$income)-1) # last 0.5%
qt(0.005, df=length(df$income)-1, lower.tail=FALSE) # last 0.5%
# Print
lower_99_t
mean(df$income)
upper_99_t
# Update Histogram
hist(df$income)
abline(v=mean(df$income),col="black")
abline(v=lower_95,col="black",lty="dashed")
abline(v=upper_95,col="black",lty="dashed")
# Scatter plot
plot(df$income,df$edu)
plot(df$income,df$edu,
col=df$cap+1) # Color over third variable (+1, because first color in R is white)
# Improve visualization and save
png(file="tutorials/02/scatter_plot.png")
plot(df$income,
df$edu,
col=df$cap+1,
xlab="Monthly net income (in Euro)",
ylab="University level education (in years)",
main="The Relationship between education and income")
# Add legend
legend(1000, 8, # x and y position of legend
legend=c("Non capital", "Capital"),
col=c("black","red"),
pch=1) # Marker type (1 is default)
dev.off()
# Boxplot
boxplot(df$income ~ df$cap,
main="Boxplot of Income by place of residence",
ylab="Euro",
xlab="Place of residence",
names=c("Non capital","Capital"))
# Improve visualization and save
png(file="tutorials/02/scatter_plot.png")
plot(df$income,
df$edu,
col=df$cap+1,
xlab="Monthly net income (in Euro)",
ylab="University level education (in years)",
main="The Relationship between education and income")
# Add legend
legend(1000, 8, # x and y position of legend
legend=c("Non capital", "Capital"),
col=c("black","red"),
pch=1) # Marker type (1 is default)
dev.off()
# Boxplot
boxplot(df$income ~ df$cap,
main="Boxplot of Income by place of residence",
ylab="Euro",
xlab="Place of residence",
names=c("Non capital","Capital"))
t.test(df$income, mu = 3034)
?t.test
t.test(df$income, mu = 3034, alternative = "less")
# We also found a much easier way to calculate the confidence intervals (!)
t.test(df$income, conf.level = 0.99, alternative = "two.sided")
# Let's double check
lower_99_t
mean(df$income)
upper_99_t
# Calculate means for subgroups
mean(df[df$cap==0, ]$income)
mean(df[df$cap==1, ]$income)
# Step by step
df$cap
df$cap==0 # Only consider cases with cap==0
df[df$cap==0, ] # Subsetting rows accordingly
df[df$cap==0, ]$income # Access variable
mean(df[df$cap==0, ]$income) # Calculate mean
# t-test
t.test(df$income ~ df$cap, alternative = "two.sided")
?t.test
# t-test
t.test(df$income ~ df$cap, alternative = "less")
?print
# Update Histogram
hist(df$income)
abline(v=mean(df$income),col="black")
abline(v=lower_95,col="black",lty="dashed")
abline(v=upper_95,col="black",lty="dashed")
# Scatter plot
plot(df$income,df$edu)
plot(df$income,df$edu,
col=df$cap+1) # Color over third variable (+1, because first color in R is white)
# Improve visualization and save
png(file="tutorials/02/scatter_plot.png")
plot(df$income,
df$edu,
col=df$cap+1,
xlab="Monthly net income (in Euro)",
ylab="University level education (in years)",
main="The Relationship between education and income")
# Add legend
legend(1000, 8, # x and y position of legend
legend=c("Non capital", "Capital"),
col=c("black","red"),
pch=1) # Marker type (1 is default)
dev.off()
# Boxplot
boxplot(df$income ~ df$cap,
main="Boxplot of Income by place of residence",
ylab="Euro",
xlab="Place of residence",
names=c("Non capital","Capital"))
t.test(df$income, mu = 3034)
?t.test
t.test(df$income, mu = 3034, alternative = "less")
# We also found a much easier way to calculate the confidence intervals (!)
t.test(df$income, conf.level = 0.99, alternative = "two.sided")
# Let's double check
lower_99_t
mean(df$income)
upper_99_t
# Calculate means for subgroups
mean(df[df$cap==0, ]$income)
mean(df[df$cap==1, ]$income)
# Step by step
df$cap
df$cap==0 # Only consider cases with cap==0
df[df$cap==0, ] # Subsetting rows accordingly
df[df$cap==0, ]$income # Access variable
mean(df[df$cap==0, ]$income) # Calculate mean
# t-test
t.test(df$income ~ df$cap, alternative = "two.sided")
?t.test
# t-test
t.test(df$income ~ df$cap, alternative = "less")
# Set working directory
setwd("/Users/paddy/OneDrive/Documents/GitHub/StatsI_Fall2023")
getwd()
# Load data
df <- read.csv("datasets/fictional_data.csv")
# First step, look at data
View(df)
head(df)
str(df) # Structure of R object
?str
mean(df$income) # Central tendency, mean
var(df$income) # Variability, variance
sd(df$income) # Variability, standard deviation
sd(df$income)/sqrt(length(df$income)) # Variability, standard **error**
# Step by step
df$income # Access variable
length(df$income) # Number of observations
sqrt(length(df$income)) # Take square root
sqrt(19)
# Get summary statistics for entire dataset
summary(df)
# Some quick visualizations, to look at distribution
hist(df$income,
#breaks = 20,
main="Monthly net income",
xlab="Euro")
plot(density(df$incom),
main="Monthly net income",
xlab="Euro")
# Which kind of inferences can we make with regards to the population,
# based on the sample data?
mean(df$income) # Sample mean is estimate for population mean
sd(df$income)/sqrt(length(df$income))
# What do we need?
mean(df$income) # Point estimate
sd(df$income)/sqrt(length(df$income)) # Standard error
# The **approximate** solution
# Lower bound, 95 confidence level
upper_95 = mean(df$income)+(1.96*sd(df$income)/sqrt(length(df$income)))
# Upper bound, 95 confidence level
lower_95 = mean(df$income)-(1.96*sd(df$income)/sqrt(length(df$income)))
# Print
lower_95
mean(df$income)
upper_95
# The **precise** solution, using normal distribution
# Lower bound, 95 confidence level
lower_95_n <- qnorm(0.025,
mean = mean(df$incom),
sd = (sd(df$income)/sqrt(length(df$income))))
# Upper bound, 95 confidence level
upper_95_n <- qnorm(0.975,
mean = mean(df$income),
sd = (sd(df$incom)/sqrt(length(df$income))))
# Step by step
?qnorm
qnorm(0.025) # value for first 2.5%
qnorm(0.975) # value last 2.5%
qnorm(0.025, mean=2, sd=0.4) # Change mean and standard error
# Print
lower_95_n
mean(df$income)
upper_95_n
# The **precise** solution, using t distribution
t_score <- qt(0.995, df=length(df$income)-1)
lower_99_t <- mean(df$income)-(t_score)*(sd(df$income)/sqrt(length(df$income)))
upper_99_t <- mean(df$income)+(t_score)*(sd(df$income)/sqrt(length(df$income)))
# Step by step
?qt
qt(0.005, df=length(df$income)-1) # critical value for first 0.5%
qt(0.995, df=length(df$income)-1) # last 0.5%
qt(0.005, df=length(df$income)-1, lower.tail=FALSE) # last 0.5%
# Print
lower_99_t
mean(df$income)
upper_99_t
# Update Histogram
hist(df$income)
abline(v=mean(df$income),col="black")
abline(v=lower_95,col="black",lty="dashed")
abline(v=upper_95,col="black",lty="dashed")
# Scatter plot
plot(df$income,df$edu)
plot(df$income,df$edu,
col=df$cap+1) # Color over third variable (+1, because first color in R is white)
# Improve visualization and save
png(file="tutorials/02/scatter_plot.png")
plot(df$income,
df$edu,
col=df$cap+1,
xlab="Monthly net income (in Euro)",
ylab="University level education (in years)",
main="The Relationship between education and income")
# Add legend
legend(1000, 8, # x and y position of legend
legend=c("Non capital", "Capital"),
col=c("black","red"),
pch=1) # Marker type (1 is default)
dev.off()
# Boxplot
boxplot(df$income ~ df$cap,
main="Boxplot of Income by place of residence",
ylab="Euro",
xlab="Place of residence",
names=c("Non capital","Capital"))
t.test(df$income, mu = 3034)
?t.test
t.test(df$income, mu = 3034, alternative = "less")
source("~/GitHub/StatsI_Fall2023/tutorials/02/02_tutorial_HF.R", echo=TRUE)
?t.test
# We also found a much easier way to calculate the confidence intervals (!)
t.test(df$income, conf.level = 0.99, alternative = "two.sided")
# Let's double check
lower_99_t
mean(df$income)
upper_99_t
# Calculate means for subgroups
mean(df[df$cap==0, ]$income)
mean(df[df$cap==1, ]$income)
# Step by step
df$cap
df$cap==0 # Only consider cases with cap==0
df[df$cap==0, ] # Subsetting rows accordingly
df[df$cap==0, ]$income # Access variable
mean(df[df$cap==0, ]$income) # Calculate mean
# t-test
t.test(df$income ~ df$cap, alternative = "two.sided")
?t.test
# t-test
t.test(df$income ~ df$cap, alternative = "less")
# Get working directory
getwd()
# Set working directory
setwd("/Users/hannahfrank/StatsI_Fall2023_prep")
# Set working directory
setwd("/Users/paddy/OneDrive/Documents/GitHub/StatsI_Fall2023")
getwd()
# Load data
df_not_tidy <- read.csv("datasets/movies.csv")
# First step, look at data
View(df_not_tidy)
str(df_not_tidy)
head(df_not_tidy)
summary(df_not_tidy)
# Load tidy version of data
# The data is prepared using the data_wraning.R script.
df <- readRDS("datasets/movies.rds")
str(df)
# First step, look at data
View(df)
class(df$genre)
levels(df$genre)
# Contingency table
table(df$genre, # Genre
df$critics_rating) # Rating
library(ggplot2)
data <- data.frame(x = rnorm(100, mean = 0, sd = 1),
y = rnorm(100, mean = 0, sd = 1))
# Create an artistic visualization using ggplot2
artistic_plot <- ggplot(data, aes(x, y)) +
geom_point(shape = 21, size = 10, color = "red", fill = "blue") +
theme_minimal() +
theme(panel.grid = element_blank(),
axis.text = element_blank(),
axis.title = element_blank(),
axis.ticks = element_blank(),
plot.margin = unit(c(1,1,1,1), "cm"))
# Save the artistic plot as an image file
ggsave("artistic_image.png", artistic_plot, width = 6, height = 6)
In this example, a random dataset of points is created, and ggplot2 is used to create an artistic visualization. The geom_point() function is customized to create a visually appealing pattern. The resulting plot is then saved as an image file ("artistic_image.png").
# Draw flower center
points(0, 0, col="yellow", pch=16, cex=3)
plot(1, type="n", xlab="", ylab="", xlim=c(-1.5, 1.5), ylim=c(-1.5, 1.5))
# Draw flower petals
for (i in 1:6) {
angle <- i * pi / 3
x <- sin(angle)
y <- cos(angle)
points <- cbind(x, y)
points <- rbind(points, c(0, 0))
polygon(points, col="pink", border="red")
}
# Draw flower center
points(0, 0, col="yellow", pch=16, cex=3)
plot(1, type="n", xlab="", ylab="", xlim=c(-1.5, 1.5), ylim=c(-1.5, 1.5))
# Draw flower petals
for (i in 1:12) {
angle <- i * pi / 6
petal_length <- 1.2 + 0.3 * cos(4 * angle)
x <- petal_length * sin(angle)
y <- petal_length * cos(angle)
points <- cbind(x, y)
points <- rbind(points, c(0, 0))
polygon(points, col="pink", border="red")
}
# Draw flower center
points(0, 0, col="yellow", pch=16, cex=2.5)
# Given data
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
# Calculate sample mean and standard deviation
sample_mean <- mean(y)
sample_sd <- sd(y)
sample_size <- length(y)
# Degrees of freedom for t-distribution
df <- sample_size - 1
# Calculate t-critical value for a 90% confidence interval
t_critical <- qt(0.95, df)
# Calculate margin of error
margin_of_error <- t_critical * (sample_sd / sqrt(sample_size))
# Calculate confidence interval bounds
lower_bound <- sample_mean - margin_of_error
upper_bound <- sample_mean + margin_of_error
# Print the confidence interval
print(paste("90% Confidence Interval (t-distribution): [", lower_bound, ",", upper_bound, "]"))
print(lower_bound)
print(upper_bound)
