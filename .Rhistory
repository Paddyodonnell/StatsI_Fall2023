(((F02-Fe2)^2)/Fe2)+
(((F03-Fe3)^2)/Fe3)+
(((F04-Fe4)^2)/Fe4)+
(((F05-Fe5)^2)/Fe5)+
(((F06-Fe6)^2)/Fe6)
} -> test.result
print(test.result)
pchisq(test.result, df=2, lower.tail = FALSE)
west_bengal_data <- read.csv("https://raw.githubusercontent.com/kosukeimai/qss/master/PREDICTION/women.csv")
#By hand bivariate regression analysis.
#First calculate the correlation coefficient, test statistic (t_stat), and p-value.
{wbd_matrix <- as.matrix(west_bengal_data)
r <- cov(wbd_matrix)[3,6]/(sd(wbd_matrix[,3])*sd(wbd_matrix[,6]))
n <- dim(wbd_matrix)[1]
t_stat <- (r*sqrt(n-2))/sqrt(1-r^2)
p_value <- 2*pt(t_stat,n-2,lower.tail=FALSE)
print(r)
print(t_stat)
print(p_value)
}
#Calculate the p-value.
{p_value <- 2*pt(t_stat,n-2,lower.tail=FALSE)
print(p_value)
}
#More efficiently, not by hand.
#find r, the correlation coefficient.
cor(wbd_matrix[,3], wbd_matrix[,6], method = "pearson")
#Hypothesis test.
cor.test(wbd_matrix[,3], wbd_matrix[,6])
model <- lm(water ~ female, data=west_bengal_data)
summary(model)
model <- lm(water ~ reserved, data=west_bengal_data)
summary(model)
summary(model)
(14.738-0)/2.286
(9.252-0)/3.948
#By hand bivariate regression analysis.
#First calculate the correlation coefficient, test statistic (t_stat), and p-value.
{wbd_matrix <- as.matrix(west_bengal_data)
r <- cov(wbd_matrix)[3,6]/(sd(wbd_matrix[,3])*sd(wbd_matrix[,6]))
n <- dim(wbd_matrix)[1]
t_stat <- (r*sqrt(n-2))/sqrt(1-r^2)
p_value <- 2*pt(t_stat,n-2,lower.tail=FALSE)
print(r)
print(t_stat)
print(p_value)
}
#Calculate the p-value.
{p_value <- 2*pt(t_stat,n-2,lower.tail=FALSE)
print(p_value)
}
#More efficiently, not by hand.
#find r, the correlation coefficient.
cor(wbd_matrix[,3], wbd_matrix[,6], method = "pearson")
#Hypothesis test.
cor.test(wbd_matrix[,3], wbd_matrix[,6])
west_bengal_data <- read.csv("https://raw.githubusercontent.com/kosukeimai/qss/master/PREDICTION/women.csv")
View(west_bengal_data)
str(west_bengal_data)
?lm
model <- lm(water ~ reserved, data=west_bengal_data)
summary(model)
#By hand bivariate regression analysis, pearson.
#First calculate the correlation coefficient, test statistic (t_stat), and p-value.
{wbd_matrix <- as.matrix(west_bengal_data)
r <- cov(wbd_matrix)[3,6]/(sd(wbd_matrix[,3])*sd(wbd_matrix[,6]))
n <- dim(wbd_matrix)[1]
t_stat <- (r*sqrt(n-2))/sqrt(1-r^2)
p_value <- 2*pt(t_stat,n-2,lower.tail=FALSE)
print(r)
print(t_stat)
print(p_value)
}
model1 <- lm(water ~ reserved, data=west_bengal_data)
summary(model1)
#Test statistic from intercept of model1.
(14.738-0)/2.286
14.738+(9.560*1)
(9.252-0)/3.948
#Model for reservation policy.
14.738+(9.560*1)
#Model for villages without the resvervation policy.
14.738+(9.560*0)
#Model for reservation policy.
14.738+(9.252*1)
#Model for villages without the resvervation policy.
14.738+(9.252*0)
#Model for reservation policy.
14.738+(9.252*1)
#Model for villages without the reservation policy.
14.738+(9.252*0)
model1 <- lm(water ~ reserved, data=west_bengal_data)
summary(model1)
#Test statistic from intercept of model1.
(14.738-0)/2.286
#Model for reservation policy.
14.738+(9.252*1)
#Model for villages without the reservation policy.
14.738+(9.252*0)
summary(model1)
4.22e-10
# Get working directory
getwd()
# Set working directory
setwd("/Users/paddy/OneDrive/Documents/GitHub/StatsI_Fall2023")
getwd()
# Install and load packages
# Adopted from: https://stackoverflow.com/questions/4090169/elegant-way-to-check-for-missing-packages-and-install-them
if(!require(wbstats)){
install.packages("wbstats")
library(wbstats)}
if(!require(tidyverse)){
install.packages("tidyverse")
library(tidyverse)}
if(!require(ggplot2)){
install.packages("ggplot2")
library(ggplot2)}
if(!require(stargazer)){
install.packages("stargazer")
library(stargazer)}
# Load data from World Bank API
wb <- wb(country=c("AF","BRA","ITA","NGA","SWE","UGA"),
indicator=c("NY.GDP.PCAP.CD", # GDP per capita (current US$)
"SP.POP.TOTL", # Population, total
"SE.SEC.ENRR", #  School enrollment, secondary (% gross)
"SH.DYN.MORT"), # Mortality rate, under-5 (per 1,000 live births)
startdate = 2000, enddate = 2020)
View(wb)
# Reshape data from long to wide (put rows in columns)
wb_re <- reshape(wb[, c("country","iso3c","date","indicatorID","value")], # df
timevar = "indicatorID", # New columns
idvar = c("country","date","iso3c"), # Identifiers for rows
direction = "wide")
View(wb_re)
# Load Quality of Government data
qog <- read_csv("https://www.qogdata.pol.gu.se/data/qog_bas_ts_jan23.csv")
View(qog)
# Merge
df <- merge(wb_re, # Left df
qog[, c("ccodealp","year","bmr_dem")], # Right df
by.x=c("date","iso3c"), # Merge variables in left
by.y=c("year","ccodealp"), # Merge variables in right
all.x=TRUE, # Merge operation, only keep left
sort=FALSE) # Do not sort observations
View(df)
# Rename columns
names(df)
names(df)[4] <- "gdp_per_cap"
names(df)[5] <- "pop_size"
names(df)[6] <- "sec_enrol"
names(df)[7] <- "mort"
names(df)[8] <- "democracy"
View(df)
# Save df
write.csv(df, "datasets/df_income_mortality.csv")
# Load df
df <- read_csv("datasets/df_income_mortality.csv")
View(df)
# Get unique countries in df
df_uni <- select(df, country) # Select variable
df_uni <- distinct(df_uni, country) # Get unique values
df_uni
# Get unique countries in df, using the pipe
df %>%
select(country) %>%
distinct(country)
# Filter (subset is base R)
df_s <- filter(df, country %in% c("Afghanistan","Italy"))
df_s
# Get the mean income and max child mortality for each year
df_grouped <- group_by(df, date) # Group by year
df_mean_inc <- summarize(df_grouped,
n=n(), # Counts
mean_inc=mean(gdp_per_cap), # Mean
max_mort=max(mort)) # Max
df_mean_inc
# Check if df has missing values
sum(is.na(df$gdp_per_cap))
sum(is.na(df$mort))
# Option I: Replace missing values with zero, but be careful!
df_na <- df %>% replace(is.na(.), 0)
# Option II: Replace missing values with mean
df_na <- df # Copy
?replace_na
df_na$gdp_per_cap <- replace_na(data=df_na$gdp_per_cap,
replace=mean(df_na$gdp_per_cap, # Value to replace NA with
na.rm = TRUE))
# Step by step:
mean(df_na$gdp_per_cap, na.rm = TRUE)
# Option III: Replace missing values with group mean
df_na <- group_by(df_na, country) # Group
df_na <- mutate(df_na, # Replace with mean if value is missing
sec_enrol = ifelse(is.na(sec_enrol),
mean(sec_enrol, na.rm = TRUE),
sec_enrol))
# Re-coding variables, in Base R
# Create categorical income variable
df_na$income_cat <- 0 # Create empty variable
summary(df_na$gdp_per_cap) # Check quantile
df_na$income_cat[df_na$gdp_per_cap>756.8] <- 1 # Place step by step
df_na$income_cat[df_na$gdp_per_cap>3171.6] <- 2
df_na$income_cat[df_na$gdp_per_cap>31768.3] <- 3
View(df_na)
# Convert into factor
typeof(df_na$income_cat)
df_na$income_cat <- factor(df_na$income_cat,
labels = c("low","medium_low","medium_high","high"))
View(df_na)
# Re-coding variables, in tidyverse
# Create categorical income variable
quantile(df_na$gdp_per_cap) # Check quantiles
df_na <- df_na # Copy
df_na <- mutate(df_na, income_cat2=cut(gdp_per_cap,
breaks=quantile(df_na$gdp_per_cap),
labels=c("low","medium_low","medium_high","high")))
typeof(df_na$income_cat)
View(df_na)
# Step by step:
cut(df_na$gdp_per_cap,breaks=c(0,600,800,Inf)) # Define breaks
cut(df_na$gdp_per_cap,breaks=quantile(df_na$gdp_per_cap)) # Use quantiles as breaks
cut(df_na$gdp_per_cap,breaks=quantile(df_na$gdp_per_cap),labels=c("low","medium_low","medium_high","high")) # Add labels
# Drop missing values
df <- df[complete.cases(df), ]
# Scatter plot
scatter <-
ggplot(data = df_na, # --> data
mapping = aes(x = gdp_per_cap,
y = mort)) +  # --> aesthetic mapping
geom_point() # --> geometric object, scatter plot
# Print plot object
scatter
# Scatter plot, log-transform income
hist(df_na$gdp_per_cap)
hist(log(df_na$gdp_per_cap))
# Scatter plot
scatter <-
ggplot(data = df_na,
mapping = aes(x = log(gdp_per_cap), # log-transform
y = mort)) +
geom_point()
scatter
# Scatter plot
scatter <-
ggplot(data = df_na,
mapping = aes(x = log(gdp_per_cap), # log-transform
y = mort,
size = sec_enrol)) +
geom_point()
scatter
# Improve visualization and save
scatter <- ggplot(data = df_na,
mapping = aes(x = log(gdp_per_cap), # log-transform
y = mort,
size = sec_enrol)) +
geom_point()  +
labs(x = "GDP per capita (log)", # Add labels
y = "Child mortality",
size = "Population size") +
theme_classic() + # Change theme
theme(legend.box.background = element_rect(size = 0.1), # Change background
legend.position = c(0.85, 0.85)) # Change position of legend
ggsave(scatter, file = "tutorials/05/scatter.png")
scatter
# Fit model
model <- lm(mort ~ gdp_per_cap, data=df_na)
summary(model)
View(df_na)
View(df_na)
# Re-scale income
df_na$gdp_per_cap_1000 <- df_na$gdp_per_cap/1000
model <- lm(mort ~ gdp_per_cap_1000, data=df_na)
summary(model)
# Export Latex table
stargazer(model)
# Fit model
model <- lm(mort ~ democracy, data=df_na)
summary(model)
west_bengal_data <- read.csv("https://raw.githubusercontent.com/kosukeimai/qss/master/PREDICTION/women.csv")
View(west_bengal_data)
str(west_bengal_data)
######################################################################
#By hand bivariate regression analysis, pearson.
#First calculate the correlation coefficient, test statistic (t_stat), and p-value.
{wbd_matrix <- as.matrix(west_bengal_data)
r <- cov(wbd_matrix)[3,6]/(sd(wbd_matrix[,3])*sd(wbd_matrix[,6]))
n <- dim(wbd_matrix)[1]
t_stat <- (r*sqrt(n-2))/sqrt(1-r^2)
p_value <- 2*pt(t_stat,n-2,lower.tail=FALSE)
print(r)
print(t_stat)
print(p_value)
}
#Not by hand.
#find r, the correlation coefficient.
cor(wbd_matrix[,3], wbd_matrix[,6], method = "pearson")
#Hypothesis test.
cor.test(wbd_matrix[,3], wbd_matrix[,6])
model1 <- lm(water ~ reserved, data=west_bengal_data)
summary(model1)
#Test statistic from intercept of model1.
(14.738-0)/2.286
#Test statistic.
(9.252-0)/3.948
#Export model1 as LaTex code.
stargazer(model1)
4.22e-10
#Model for reservation policy.
14.738+(9.252*1)
#Model for villages without the reservation policy.
14.738+(9.252*0)
14.748+(2.286*6.44)
14.748-(2.286*6.44)
#Model for reservation policy.
14.738+(9.252*1)
#Model for villages without the reservation policy.
14.738+(9.252*0)
#Model for reservation policy.
14.738+(9.252*1)
#Model for villages without the reservation policy.
14.738+(9.252*0)
#Model for reservation policy.
14.738+(9.252*1)
#Model for villages without the reservation policy.
14.738+(9.252*0)
model1 <- lm(water ~ reserved, data=west_bengal_data)
summary(model1)
14.748+(1.97*6.44)
14.748-(1.97*6.44)
14.748+(1.97*6.44)
14.748-(1.97*6.44)
9.252+(1.97*3.948)
9.252-(1.97*3.948)
confint(model1, "reserved", level=0.95)
confint(model1, "water", level=0.95)
model1 <- lm(water ~ reserved, data=west_bengal_data)
summary(model1)
confint(model1, "reserved", level=0.95)
confint(model1, "water", level=0.95)
confint(model1, "water", level=0.95)
confint(model1, "reserved", level=0.95)
9.252+(1.97*2.344)
14.748+(1.97*2.344)
14.748+(1.97*6.44)
14.748-(1.97*6.44)
9.252+(1.97*3.948)
9.252-(1.97*3.948)
9.252+(1.97*3.948)
9.252-(1.97*3.948)
plot(west_bengal_data$reserved, west_bengal_data$water)
ggplot(west_bengal_data, aes(x = reserved, y = water)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "blue") +
labs(x = "Reservation Policy (0 = Not Reserved, 1 = Reserved)",
y = "Number of Water Facilities",
title = "Relationship between Reservation Policy and Water Facilities")+
theme_minimal()
scatterplot(west_bengal_data$reserved, west_bengal_data$water)
ggplot(west_bengal_data, aes(x = reserved, y = water)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "blue") +
labs(x = "Reservation Policy (0 = Not Reserved, 1 = Reserved)",
y = "Number of Water Facilities",
title = "Relationship between Reservation Policy and Water Facilities")+
theme_minimal()
model1 <- lm(water ~ reserved, data=west_bengal_data)
summary(model1)
confint(model1, "reserved", level=0.95)
9.252+(1.97*3.948)
9.252-(1.97*3.948)
#Write table into R with code.
{observed_data <- matrix(c(14, 6, 7, 7, 7, 1), nrow = 2, byrow = TRUE)
colnames(observed_data) <- c("Not Stopped", "Bribe Requested", "Stopped/given warning")
row.names(observed_data) <- c("Upper class", "Lower class")
}
#View the table to check it is correct.
View(observed_data)
#Run the chi squared test.
chi_test <- chisq.test(observed_data)
#Extract the required data.
ls(chi_test)
chi_test$stdres
model1 <- lm(water ~ reserved, data=west_bengal_data)
summary(model1)
scatterplot(west_bengal_data$reserved, west_bengal_data$water)
model1 <- lm(water ~ reserved, data=west_bengal_data)
summary(model1)
model1 <- lm(water ~ reserved, data=west_bengal_data)
summary(model1)
gdp <- c(38,38,35,90)
var(gdp)
?var
mean(gdp)
39-m
38-m
m <- mean(gdp)
39-m
38-m
35-m
90-m
(39-m)^2
(38-m)^2
(35-m)^2
(90-m)^2
{(39-m)^2
+
(38-m)^2
+
(35-m)^2
+
(90-m)^2
}
{(39-m)^2+
(38-m)^2+
(35-m)^2+
(90-m)^2
}
sum <- {(39-m)^2+
(38-m)^2+
(35-m)^2+
(90-m)^2
}
sum/3
var(gdp)
sum <- {(38-m)^2+
(38-m)^2+
(35-m)^2+
(90-m)^2
}
sum/3
sd(gdp)
?sd
sum2 <- {(38-m)+
(38-m)+
(35-m)+
(90-m)
}
sum2/4
sum2 <- {(38-m)+
(38-m)+
(35-m)+
(90-m)
}
sum2/4
gdp <- c(38,38,35,90)
m <- mean(gdp)
sum2 <- {(38-m)+
(38-m)+
(35-m)+
(90-m)
}
sum2/4
print(sum2)
sum2 <- {(38-m)+
(38-m)+
(35-m)+
(90-m)
}
sum2 <- {(38-m)+
(38-m)+
(35-m)+
(90-m)
}
print(sum2)
38-m
38-m
38-m
35-m
90-m
sd(gdp)
sum <- {(38-m)^2+
(38-m)^2+
(35-m)^2+
(90-m)^2
}
sum/4
gdp <- c(38,38,35,90)
var(gdp)
m <- mean(gdp)
sum <- {(38-m)^2+
(38-m)^2+
(35-m)^2+
(90-m)^2
}
sum/3
variance <- sum/3
sqrt(variance)
sd(gdp)
1.753*(0.8/4)
error <- (1.753*(0.8/4))
14.5+error
15.5-error
error <- (1.753*(0.8/4))
print(error)
14.5+error
14.5+error
14.5-error
sqrt(variance)
print(varience)
print(variance)
217-225/0.05
(217-225)/0.05
(217-225)/40
sqrt(100)
(86/243)*100
sqrt((19(1-19))/200)
sqrt((19(1-19))/200)
sqrt((19(1-19))/200))
(19(1-19))/200
sqrt((19*(1-19))/200)
19*-18
-342/200
sqrt(-1.71)
